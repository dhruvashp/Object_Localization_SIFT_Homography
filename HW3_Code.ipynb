{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function performs SIFT on an image and returns keypoints and descriptors\n",
    "\n",
    "def kp_des(img):\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    return kp, des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for SIFT visualization returning visualized image\n",
    "\n",
    "def viz_sift(img,kp):\n",
    "    viz_img = cv2.drawKeypoints(img,kp,None,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    cv2.imshow('Visualization',viz_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return viz_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for BF matching with KNN match (k=num_of_match) returning the match list \n",
    "# k >= 2\n",
    "\n",
    "def match_features(section_des,whole_des,num_of_match):\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(section_des,whole_des,k=num_of_match)\n",
    "    return matches   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for refining matches obtained from BF + KNN matching which returns a list of single length lists of good matches\n",
    "# k >= 2\n",
    "# Thus, we assume that we have for each query point at least two matches so that ratio test can be performed \n",
    "# Also, length of the returned list from match_refiner() gives us the total valid/refined/good matches\n",
    "# So, separate function for total valid matches not needed\n",
    "\n",
    "def match_refiner(matches):\n",
    "    good_matches = []\n",
    "    for match_list in matches:\n",
    "        distance_list = []\n",
    "        for individual_matches in match_list:\n",
    "            distance_list.append(individual_matches.distance)\n",
    "        distance_sorted = distance_list.copy()\n",
    "        distance_sorted.sort()\n",
    "        if (distance_sorted[0]/distance_sorted[1]) < 0.75:\n",
    "            min_distance = min(distance_list)\n",
    "            indx = distance_list.index(min_distance)\n",
    "            best_match = match_list[indx]\n",
    "            good_matches.append([best_match])\n",
    "    return good_matches\n",
    "\n",
    "# We select matches using the simple ratio test with a threshold of 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to further select top n matches from the list of good matches, returning these top matches\n",
    "# input 1 = refined matches (valid, filtered matches, a query has a single match)\n",
    "# input 2 = n (number of top matches needed)\n",
    "# output = top matches list\n",
    "\n",
    "def top_n_matches(good_matches,n):\n",
    "    distances = []\n",
    "    for match_list in good_matches:\n",
    "        match = match_list[0]\n",
    "        distances.append(match.distance)\n",
    "    distances_np = np.array(distances)\n",
    "    indx = np.argsort(distances_np)\n",
    "    indx = list(indx)\n",
    "    if n >= len(good_matches):\n",
    "        top_matches = good_matches\n",
    "    else:\n",
    "        indx_slice = indx[0:n]\n",
    "        top_matches = [good_matches[i] for i in indx_slice]\n",
    "    return top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for match visualizer displaying the matches and returning the visualized image\n",
    "\n",
    "def viz_match(sec,whole,kp_sec,kp_whole,matches):\n",
    "    viz_img = cv2.drawMatchesKnn(sec,kp_sec,whole,kp_whole,matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.imshow('Visualization',viz_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return viz_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the following tasks\n",
    "# 1. Using valid matches to compute H via RANSAC (and returning H)\n",
    "# 2. Returning relevant mask depicting inliers and outliers for visualization\n",
    "# 3. Returning inliers count\n",
    "# 4. Returning outliers count\n",
    "# 5. Returning inlier matches\n",
    "# 6. Returning top n inlier matches (with minimum error between projected source point and corresponding match point)\n",
    "# 7. Returning a flag, flag = 1 if object found, flag = 0 if object not found\n",
    "# Assumption - It has obviously been assumed here that top n matches refers to top n inlier matches\n",
    "\n",
    "def compute_homography(kp_sec,kp_whole,valid_matches,match_threshold,inlier_threshold,n):\n",
    "    if len(valid_matches) < match_threshold:\n",
    "        flag = 0\n",
    "        # print('Not enough valid matches to compute homography, object not found')\n",
    "        return None,None,None,None,None,None,flag\n",
    "    else:\n",
    "        flag = 1\n",
    "        sec_pts = np.float32([kp_sec[match[0].queryIdx].pt for match in valid_matches]).reshape(-1,1,2) \n",
    "        whole_pts = np.float32([kp_whole[match[0].trainIdx].pt for match in valid_matches]).reshape(-1,1,2)\n",
    "        H,mask = cv2.findHomography(sec_pts,whole_pts,cv2.RANSAC,inlier_threshold)\n",
    "        mask_list = mask.ravel().tolist()\n",
    "        inlier_count = 0\n",
    "        for status in mask_list:\n",
    "            if status == 1:\n",
    "                inlier_count = inlier_count + 1\n",
    "        outlier_count = len(mask_list) - inlier_count\n",
    "        inlier_matches = [valid_matches[i] for i in range(len(valid_matches)) if mask_list[i]==1]\n",
    "        if n >= len(inlier_matches):\n",
    "            top_inlier_matches = inlier_matches\n",
    "        else:\n",
    "            l2_error = []\n",
    "            for match in inlier_matches:\n",
    "                source_pt = np.float32(kp_sec[match[0].queryIdx].pt).reshape(-1,1,2)\n",
    "                destination_pt = np.float32(kp_whole[match[0].trainIdx].pt).reshape(-1,1,2)\n",
    "                projected_pt = cv2.perspectiveTransform(source_pt,H)\n",
    "                l2_error.append(np.linalg.norm(destination_pt.flatten()-projected_pt.flatten()))\n",
    "            l2_error_np = np.array(l2_error)\n",
    "            indx = np.argsort(l2_error_np)\n",
    "            indx_slice = indx[0:n]\n",
    "            top_inlier_matches = [inlier_matches[i] for i in indx_slice]\n",
    "        return H,mask_list,inlier_count,outlier_count,inlier_matches,top_inlier_matches,flag        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize inlier and top inlier matches\n",
    "\n",
    "def viz_match_inlier(sec,whole,kp_sec,kp_whole,matches,flag):\n",
    "    if flag == 1:\n",
    "        viz_img = viz_match(sec,whole,kp_sec,kp_whole,matches)\n",
    "        return viz_img\n",
    "    else:\n",
    "        # print('Not enough valid matches, object not found, inlier/outlier matches do not exist, refer normal matches for some visualization')\n",
    "        return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize source object found in the destination image\n",
    "\n",
    "def viz_found(sec,whole,kp_sec,kp_whole,matches,H,flag):\n",
    "    if flag == 1:\n",
    "        h,w,d = sec.shape\n",
    "        edges = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "        transformed_edges = cv2.perspectiveTransform(edges,H)\n",
    "        whole_copy = whole.copy() # polylines modifies input image\n",
    "        whole_new = cv2.polylines(whole_copy,[np.int32(transformed_edges)],True,255,3,cv2.LINE_AA)\n",
    "        viz_img = viz_match(sec,whole_new,kp_sec,kp_whole,matches)\n",
    "        return viz_img\n",
    "    else:\n",
    "        # print('Object not found')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the relevant images\n",
    "\n",
    "tall = cv2.imread('HW3_Data\\dst_0.jpg')\n",
    "flat = cv2.imread('HW3_Data\\dst_1.jpg')\n",
    "finance = cv2.imread('HW3_Data\\src_0.jpg')\n",
    "deep = cv2.imread('HW3_Data\\src_1.jpg')\n",
    "market = cv2.imread('HW3_Data\\src_2.jpg')\n",
    "\n",
    "source = [finance,deep,market]\n",
    "destination = [tall,flat]\n",
    "source_names = ['finance','deep','market']\n",
    "destination_names = ['tall','flat']\n",
    "\n",
    "# The number of images are small so I have directly read them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'finance', 'destination': 'tall', 'source_total_features': 5259, 'destination_total_features': 49979, 'total_matches': 219, 'image_found_flag': 1, 'homography_matrix': [[0.3123722114367278, -1.1888547651125412, 2313.1550796841498], [1.322656677299396, 0.0741637350945761, -38.70257320341777], [0.0001631382402320756, -0.0002729697944438451, 0.9999999999999999]], 'total_inliers': 43, 'total_outliers': 176}\n",
      "{'source': 'finance', 'destination': 'flat', 'source_total_features': 5259, 'destination_total_features': 10625, 'total_matches': 529, 'image_found_flag': 1, 'homography_matrix': [[0.3310325156783638, 0.007400795928463198, 461.44558094524683], [-0.22177282133164553, 0.29138771574706246, 202.03239040578023], [-7.14891120100088e-05, -0.00016647932449307274, 1.0]], 'total_inliers': 244, 'total_outliers': 285}\n",
      "{'source': 'deep', 'destination': 'tall', 'source_total_features': 42457, 'destination_total_features': 49979, 'total_matches': 155, 'image_found_flag': 1, 'homography_matrix': [[0.7695658731461521, 0.20467223119417569, 683.2542804212828], [0.4033565452978393, 1.2302643586482171, 1336.6429608994656], [-8.579055814328569e-05, 0.00020423848925519628, 1.0]], 'total_inliers': 23, 'total_outliers': 132}\n",
      "{'source': 'deep', 'destination': 'flat', 'source_total_features': 42457, 'destination_total_features': 10625, 'total_matches': 606, 'image_found_flag': 1, 'homography_matrix': [[0.4530478063375906, -0.08940463729965027, 884.4439834306285], [0.014695707321243942, 0.3940353440435085, 75.46820645606752], [1.383680441465586e-05, -6.97128183650531e-05, 1.0]], 'total_inliers': 426, 'total_outliers': 180}\n",
      "{'source': 'market', 'destination': 'tall', 'source_total_features': 13004, 'destination_total_features': 49979, 'total_matches': 1241, 'image_found_flag': 1, 'homography_matrix': [[0.8265864611624282, -0.1405614215327199, 1420.8271646418307], [0.04981197326125285, 0.16332296088212556, 2370.101710708955], [4.6140060379593796e-05, -0.0001822291433482743, 0.9999999999999999]], 'total_inliers': 679, 'total_outliers': 562}\n",
      "{'source': 'market', 'destination': 'flat', 'source_total_features': 13004, 'destination_total_features': 10625, 'total_matches': 1047, 'image_found_flag': 1, 'homography_matrix': [[0.21195761168549962, -0.39243909276394046, 1485.9702580643375], [0.31045663741662893, 0.25830188789065633, 89.99268304264801], [-6.696036887837295e-05, -3.476993060129463e-05, 1.0]], 'total_inliers': 401, 'total_outliers': 646}\n"
     ]
    }
   ],
   "source": [
    "source_indexer = -1\n",
    "for sec in source:\n",
    "    source_indexer = source_indexer + 1\n",
    "    destination_indexer = -1\n",
    "    for whole in destination:\n",
    "        destination_indexer = destination_indexer + 1\n",
    "        data_dict = {}\n",
    "        data_dict['source'] = source_names[source_indexer]\n",
    "        data_dict['destination'] = destination_names[destination_indexer]\n",
    "        base_name = str(source_names[source_indexer]) + str('_') + str(destination_names[destination_indexer])\n",
    "        if os.path.isdir(base_name):\n",
    "            shutil.rmtree(base_name)\n",
    "            os.mkdir(base_name)\n",
    "        else:\n",
    "            os.mkdir(base_name)\n",
    "        kp_sec,des_sec = kp_des(sec)\n",
    "        kp_whole,des_whole = kp_des(whole)\n",
    "        data_dict['source_total_features'] = len(kp_sec)\n",
    "        data_dict['destination_total_features'] = len(kp_whole)\n",
    "        sift_sec = viz_sift(sec,kp_sec)\n",
    "        sift_whole = viz_sift(whole,kp_whole)\n",
    "        cv2.imwrite(str(base_name)+str('\\\\')+str('Source_SIFT.jpg'),sift_sec)\n",
    "        cv2.imwrite(str(base_name)+str('\\\\')+str('Destination_SIFT.jpg'),sift_whole)\n",
    "        all_matches = match_features(des_sec,des_whole,2)\n",
    "        good_matches = match_refiner(all_matches)\n",
    "        top_matches = top_n_matches(good_matches,20)\n",
    "        data_dict['total_matches'] = len(good_matches)\n",
    "        all_viz = viz_match(sec,whole,kp_sec,kp_whole,all_matches)\n",
    "        good_viz = viz_match(sec,whole,kp_sec,kp_whole,good_matches)\n",
    "        top_viz = viz_match(sec,whole,kp_sec,kp_whole,top_matches)\n",
    "        cv2.imwrite(str(base_name)+str('\\\\')+str('All_Matches.jpg'),all_viz)\n",
    "        cv2.imwrite(str(base_name)+str('\\\\')+str('Good_Matches.jpg'),good_viz)\n",
    "        cv2.imwrite(str(base_name)+str('\\\\')+str('Top_Matches.jpg'),top_viz)\n",
    "        H,mask_list,inlier_count,outlier_count,inlier_matches,top_inlier_matches,flag = compute_homography(kp_sec,kp_whole,good_matches,10,5.0,10)\n",
    "        data_dict['image_found_flag'] = flag\n",
    "        data_dict['homography_matrix'] = H.tolist()\n",
    "        data_dict['total_inliers'] = inlier_count\n",
    "        data_dict['total_outliers'] = outlier_count\n",
    "        inlier_viz = viz_match_inlier(sec,whole,kp_sec,kp_whole,inlier_matches,flag)\n",
    "        top_inlier_viz = viz_match_inlier(sec,whole,kp_sec,kp_whole,top_inlier_matches,flag)\n",
    "        projected_viz = viz_found(sec,whole,kp_sec,kp_whole,top_inlier_matches,H,flag)\n",
    "        if flag == 1:\n",
    "            cv2.imwrite(str(base_name)+str('\\\\')+str('Inlier_Matches.jpg'),inlier_viz)\n",
    "            cv2.imwrite(str(base_name)+str('\\\\')+str('Top_Inlier_Matches.jpg'),top_inlier_viz)\n",
    "            cv2.imwrite(str(base_name)+str('\\\\')+str('Projected_Source.jpg'),projected_viz)\n",
    "        with open(str(base_name)+str('\\\\')+str('Matching_Data.txt'),'w') as convert_file:\n",
    "            convert_file.write(json.dumps(data_dict))   \n",
    "        print(data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
